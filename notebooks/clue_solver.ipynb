{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Solving clues with DNN!\n",
    "In this notebook, I outline the process through which the model is able to solve clues."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elasticsearch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdrqa\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparse\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcorenlp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CoreNLPParser\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdrqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtokenizers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SimpleTokenizer, CoreNLPTokenizer\n",
      "File \u001B[0;32m~/proj_ssd/shor.tz/lib/DrQA/drqa/__init__.py:22\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tokenizers\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m reader\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m retriever\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pipeline\n",
      "File \u001B[0;32m~/proj_ssd/shor.tz/lib/DrQA/drqa/retriever/__init__.py:38\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdoc_db\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DocDB\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtfidf_doc_ranker\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TfidfDocRanker\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01melastic_doc_ranker\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ElasticDocRanker\n",
      "File \u001B[0;32m~/proj_ssd/shor.tz/lib/DrQA/drqa/retriever/elastic_doc_ranker.py:14\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmultiprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ThreadPool\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfunctools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m partial\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01melasticsearch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Elasticsearch\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DEFAULTS\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'elasticsearch'"
     ]
    }
   ],
   "source": [
    "import drqa\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "from drqa.tokenizers import SimpleTokenizer, CoreNLPTokenizer\n",
    "drqa.tokenizers.set_default('corenlp_classpath', '../lib/DrQA/data/corenlp/*')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['Hello', 'world']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from drqa.tokenizers import CoreNLPTokenizer\n",
    "tok = CoreNLPTokenizer(mem='2g')\n",
    "tok.tokenize(\"Hello world\").words()  # Should complete immediately"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                answer                                               clue\n0                  AAA                                Big gp. of towers? \n1                  AAA                     Great \"Three R's\" report card?\n2                  AAA  Org. that can get you discounts on mortgages a...\n3                 AAAA                   Fonzi's report card, so he says?\n4                  AAH                       Sound heard from a Jacuzzi? \n...                ...                                                ...\n15211              ZOO  Scorpions song about animal exhibition (with \"...\n15212        ZOOKEEPER                             Big cat person, maybe?\n15213    ZORBATHEGRIEG                            Quinn, Norwegian style?\n15214       ZOXHZUHEHE  Do the \"I am not a crook\" thing with the doubl...\n15215  ZZTOPMANAGEMENT                 \"Sharp Dressed Man\" band's agents?\n\n[15216 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>answer</th>\n      <th>clue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAA</td>\n      <td>Big gp. of towers?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAA</td>\n      <td>Great \"Three R's\" report card?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAA</td>\n      <td>Org. that can get you discounts on mortgages a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAAA</td>\n      <td>Fonzi's report card, so he says?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAH</td>\n      <td>Sound heard from a Jacuzzi?</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15211</th>\n      <td>ZOO</td>\n      <td>Scorpions song about animal exhibition (with \"...</td>\n    </tr>\n    <tr>\n      <th>15212</th>\n      <td>ZOOKEEPER</td>\n      <td>Big cat person, maybe?</td>\n    </tr>\n    <tr>\n      <th>15213</th>\n      <td>ZORBATHEGRIEG</td>\n      <td>Quinn, Norwegian style?</td>\n    </tr>\n    <tr>\n      <th>15214</th>\n      <td>ZOXHZUHEHE</td>\n      <td>Do the \"I am not a crook\" thing with the doubl...</td>\n    </tr>\n    <tr>\n      <th>15215</th>\n      <td>ZZTOPMANAGEMENT</td>\n      <td>\"Sharp Dressed Man\" band's agents?</td>\n    </tr>\n  </tbody>\n</table>\n<p>15216 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/puns.csv',header=None,names=['answer','clue'])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from drqa import pipeline\n",
    "\n",
    "# from drqa.scripts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "word_list = pd.read_csv('../data/word_list.csv',sep=';',header=None,names=['word','score'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                    word  score\n0       03BONNIEANDCLYDE     56\n1                    0AD     25\n2                    0BC     25\n3                    0TH     75\n4                    100      5\n...                  ...    ...\n567650          ZZYZWICZ     50\n567651             ZZYZX     48\n567652               ZZZ     30\n567653           ZZZQUIL     50\n567654             ZZZZZ     46\n\n[567655 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>03BONNIEANDCLYDE</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0AD</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0BC</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0TH</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>567650</th>\n      <td>ZZYZWICZ</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>567651</th>\n      <td>ZZYZX</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>567652</th>\n      <td>ZZZ</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>567653</th>\n      <td>ZZZQUIL</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>567654</th>\n      <td>ZZZZZ</td>\n      <td>46</td>\n    </tr>\n  </tbody>\n</table>\n<p>567655 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import regex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "no_nums_wl = word_list[~word_list['word'].str.contains(r'\\d').astype(bool)]\n",
    "correct_length_wl = no_nums_wl[no_nums_wl['word'].str.len() >=3]\n",
    "correct_length_wl = correct_length_wl[correct_length_wl['word'].str.len()<=15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "               word  score\n489             AAA     50\n490            AAAA     30\n491           AAAAH     25\n492     AAAAUTOCLUB     50\n493         AAABALL     75\n...             ...    ...\n567650     ZZYZWICZ     50\n567651        ZZYZX     48\n567652          ZZZ     30\n567653      ZZZQUIL     50\n567654        ZZZZZ     46\n\n[509170 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>489</th>\n      <td>AAA</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>490</th>\n      <td>AAAA</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>491</th>\n      <td>AAAAH</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>492</th>\n      <td>AAAAUTOCLUB</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>493</th>\n      <td>AAABALL</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>567650</th>\n      <td>ZZYZWICZ</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>567651</th>\n      <td>ZZYZX</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>567652</th>\n      <td>ZZZ</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>567653</th>\n      <td>ZZZQUIL</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>567654</th>\n      <td>ZZZZZ</td>\n      <td>46</td>\n    </tr>\n  </tbody>\n</table>\n<p>509170 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_length_wl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "%load ../src/dp_wordbreak.py\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-2dab1a161a4c>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<ipython-input-13-2dab1a161a4c>\"\u001B[0;36m, line \u001B[0;32m3\u001B[0m\n\u001B[0;31m    import ../src/dp_wordbreak\u001B[0m\n\u001B[0m           ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%load?\n",
    "\n",
    "import ../src/dp_wordbreak"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/thowe/proj_ssd/shor.tz/src/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from dp_wordbreak import Trie, TrieNode, WordBreaker"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "wb = WordBreaker()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb.word_break(\"hell\",['he','ll'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from typing import List\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "wordBreak() missing 1 required positional argument: 'wordDict'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-0a38c56f1b77>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mwordBreak\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"hell\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'he'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'll'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: wordBreak() missing 1 required positional argument: 'wordDict'"
     ]
    }
   ],
   "source": [
    "wordBreak(\"hell\",['he','ll'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/11.6k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7acdc33d49a4532918033475eda64c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading metadata:   0%|          | 0.00/7.14k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0834260a4f5e44c296d82794f7a68baf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikipedia/20220301.en (download: 19.18 GiB, generated: 18.88 GiB, post-processed: Unknown size, total: 38.07 GiB) to /home/thowe/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/15.3k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d2909c9174e475085f008ada0de22a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/20.3G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "185b71b80b194ef69d1b243af904c5a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikipedia downloaded and prepared to /home/thowe/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff3e397f724c4e4288044c501c8b161a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"wikipedia\",\"20220301.en\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "ds.save_to_disk('../data/wikipedia/ds_dict')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mds\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "ds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "Creating CSV from Arrow format:   0%|          | 0/646 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cef811fd5cfb4874bddeccbb260f984b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "20278616363"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'].to_csv('../data/wikipedia/ds/wikipedia_ds.csv',num_proc=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model 'bert-base-uncased' not recognized as an MXNet model; treating as PyTorch model\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLMOptimized: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLMOptimized from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLMOptimized from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING:root:Created scorer of class 'MLMScorerPT'.\n"
     ]
    }
   ],
   "source": [
    "from hashformers import TransformerWordSegmenter as WordSegmenter\n",
    "import mxnet\n",
    "\n",
    "ws = WordSegmenter(\n",
    "    segmenter_model_name_or_path=\"gpt2\",\n",
    "    reranker_model_name_or_path=\"bert-base-uncased\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "clue_list = pd.read_csv('../data/cwdb/cwdb.txt',sep='\\t', header=None, index_col=0, names=['id','clue','answer', 'date','publisher'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "clue_list_nyt = clue_list[clue_list['publisher'] == 'NYT']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15464/2900793366.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clue_list_nyt['answer'] = list(clue_list_nyt['answer'].apply(lambda x: str(x)))\n"
     ]
    }
   ],
   "source": [
    "clue_list_nyt['answer'] = list(clue_list_nyt['answer'].apply(lambda x: str(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15464/2338771256.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clue_list_nyt['list_segmented'] = ws.segment(word_list=clue_list_nyt['answer'][:len(clue_list_nyt)])\n"
     ]
    }
   ],
   "source": [
    "clue_list_nyt['list_segmented'] = ws.segment(word_list=clue_list_nyt['answer'][:len(clue_list_nyt)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "pickle.dump(obj=clue_list_nyt,file=open('../bin/split_words_nyt.pickle','wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('O')"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clue_list_nyt['answer'].dtype\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "nyt_clue_df = pickle.load(file=open('../bin/split_words_nyt.pickle','rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "nyt_clue_df = nyt_clue_df.drop(['id',],axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               clue     answer        date  \\\n1                                         Auto org.        aaa  1990-01-01   \n2                                 Auto club letters        aaa  1995-01-01   \n4        Org. that gets members reduced motel rates        aaa  1998-01-01   \n7                                  Car owners' org.        aaa  2000-01-01   \n16                                  Motorists' grp.        aaa  2004-01-01   \n...                                             ...        ...         ...   \n2000489                                     Stomach      brook  1997-03-01   \n2000490                       Symposium, originally  wineparty  1997-03-01   \n2000491                 Time-saving means of travel        sst  1997-03-01   \n2000492                  Went over the same ground?     rehoed  1997-03-01   \n2000493               Word in a Thomas Malory title      morte  1997-03-01   \n\n        publisher list_segmented  \n1             NYT            aaa  \n2             NYT            aaa  \n4             NYT            aaa  \n7             NYT            aaa  \n16            NYT            aaa  \n...           ...            ...  \n2000489       NYT          brook  \n2000490       NYT      wineparty  \n2000491       NYT            sst  \n2000492       NYT         rehoed  \n2000493       NYT          morte  \n\n[390386 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clue</th>\n      <th>answer</th>\n      <th>date</th>\n      <th>publisher</th>\n      <th>list_segmented</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Auto org.</td>\n      <td>aaa</td>\n      <td>1990-01-01</td>\n      <td>NYT</td>\n      <td>aaa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Auto club letters</td>\n      <td>aaa</td>\n      <td>1995-01-01</td>\n      <td>NYT</td>\n      <td>aaa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Org. that gets members reduced motel rates</td>\n      <td>aaa</td>\n      <td>1998-01-01</td>\n      <td>NYT</td>\n      <td>aaa</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Car owners' org.</td>\n      <td>aaa</td>\n      <td>2000-01-01</td>\n      <td>NYT</td>\n      <td>aaa</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Motorists' grp.</td>\n      <td>aaa</td>\n      <td>2004-01-01</td>\n      <td>NYT</td>\n      <td>aaa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2000489</th>\n      <td>Stomach</td>\n      <td>brook</td>\n      <td>1997-03-01</td>\n      <td>NYT</td>\n      <td>brook</td>\n    </tr>\n    <tr>\n      <th>2000490</th>\n      <td>Symposium, originally</td>\n      <td>wineparty</td>\n      <td>1997-03-01</td>\n      <td>NYT</td>\n      <td>wineparty</td>\n    </tr>\n    <tr>\n      <th>2000491</th>\n      <td>Time-saving means of travel</td>\n      <td>sst</td>\n      <td>1997-03-01</td>\n      <td>NYT</td>\n      <td>sst</td>\n    </tr>\n    <tr>\n      <th>2000492</th>\n      <td>Went over the same ground?</td>\n      <td>rehoed</td>\n      <td>1997-03-01</td>\n      <td>NYT</td>\n      <td>rehoed</td>\n    </tr>\n    <tr>\n      <th>2000493</th>\n      <td>Word in a Thomas Malory title</td>\n      <td>morte</td>\n      <td>1997-03-01</td>\n      <td>NYT</td>\n      <td>morte</td>\n    </tr>\n  </tbody>\n</table>\n<p>390386 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_clue_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-pytorch-rapids-py",
   "language": "python",
   "display_name": "Python [conda env:pytorch-rapids]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
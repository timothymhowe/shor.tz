{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, I detail the method by which a grid is generated and subsequently filled."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.cuda.set_per_process_memory_fraction(0.9)\n",
    "rtx = torch.device('cuda')\n",
    "WEEKDAY_GRID_SIZE = 15\n",
    "total_completed = 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#  if a square is empty, 0.  If a square is black, 1.\n",
    "def bin_gridify(raw_grids):\n",
    "    binary_grids = []\n",
    "    for grid in raw_grids:\n",
    "        new_grid = [1 if x == \".\" else 0 for x in grid ]\n",
    "        binary_grids = binary_grids + [new_grid]\n",
    "    return binary_grids\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "dow_dict = pickle.load(open('../bin/pickles/dow_dict.pickle','rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "data_set = []\n",
    "for day in dow_dict.keys():\n",
    "    grid_list = dow_dict[day]\n",
    "    grid_list = bin_gridify(grid_list)\n",
    "    data_set = data_set + [grid_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mon = data_set[0]\n",
    "mon = [np.array(grid).reshape(15,15) for grid in mon if len(grid) == (15*15)]\n",
    "\n",
    "tue = data_set[1]\n",
    "tue = [np.array(grid).reshape(15,15) for grid in tue if len(grid) == (15*15)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# defining a function that checks the symmetry of the grid\n",
    "def check_symmetry(dim,grid):\n",
    "    leng = dim*dim\n",
    "    half = (leng-1)//2\n",
    "    array = grid.reshape(leng,)\n",
    "    front = array[:half]\n",
    "    back = array[-half:]\n",
    "    return (front == np.flip(back)).all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 25 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    plt.subplot(5,5,1+i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mon[i],cmap=\"Greys\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# from torchvision import datasets\n",
    "# import torchvision.transforms as transforms\n",
    "# print(\"PyTorch version is:\",torch.__version__)\n",
    "# print(\"Torchvision version is:\",torchvision.__version__)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "num_workers = 8 #\n",
    "batch_size = 32 # number of samples per batch\n",
    "\n",
    "train_data = np.array(mon+tue)\n",
    "train_data_tensor = torch.from_numpy(train_data).float()\n",
    "train_data_tensor = train_data_tensor.to(rtx)\n",
    "labels = np.array([1]*len(train_data))\n",
    "labels = torch.from_numpy(labels)\n",
    "labels = labels.to(rtx)\n",
    "\n",
    "# creating a loader to feed the models training data\n",
    "train_me = torch.utils.data.DataLoader(train_data_tensor, batch_size=batch_size,num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_demo = iter(train_me)\n",
    "images, *_ = train_demo.next()\n",
    "img = np.squeeze(images[0:15])\n",
    "fig = plt.imshow(img.cpu(),cmap='Greys',aspect=True)\n",
    "# images.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating custom class for the grid dataset in pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,input_size,hidden_dim,output_size):\n",
    "        super(Discriminator,self).__init__()\n",
    "\n",
    "        # 3 hidden layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim*4)\n",
    "        self.fc2 = nn.Linear(hidden_dim*4,hidden_dim*2)\n",
    "        self.fc3 = nn.Linear(hidden_dim*2,hidden_dim)\n",
    "\n",
    "        # output layer\n",
    "        self.fc4 = nn.Linear(hidden_dim,output_size)\n",
    "\n",
    "        # defining a dropout layer to prevent overfitting.\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "\n",
    "    def forward (self,x):\n",
    "        x = x.view(-1,WEEKDAY_GRID_SIZE*WEEKDAY_GRID_SIZE)\n",
    "        x = F.leaky_relu(self.fc1(x),0.01) # input\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.01)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.01)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # return result of output layer\n",
    "        return self.fc4(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Defining a generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "         super(Generator, self).__init__()\n",
    "\n",
    "         # Defining all hidden layers for the generator\n",
    "         self.fc1 = nn.Linear(input_size, hidden_dim)\n",
    "         self.fc2 = nn.Linear(hidden_dim, hidden_dim*2)\n",
    "         self.fc3 = nn.Linear(hidden_dim*2, hidden_dim*4)\n",
    "\n",
    "         # Defining the output layer for the generator\n",
    "         self.fc4 = nn.Linear(hidden_dim*4, output_size)\n",
    "\n",
    "         # defining the droput for the generator, which prevents overfitting.\n",
    "         self.dropout = nn.Dropout(0.2)\n",
    "    def forward(self, x):\n",
    "         # creating all hidden layers\n",
    "         x = F.relu(self.fc1(x)) # (input, negative_slope=0.2)\n",
    "         x = self.dropout(x) # dropout to reduce overfit\n",
    "         x = F.relu(self.fc2(x))\n",
    "         x = self.dropout(x)\n",
    "         x = F.relu(self.fc3(x))\n",
    "         x = self.dropout(x)\n",
    "\n",
    "         # return result of the output layer\n",
    "         return torch.tanh(self.fc4(x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining initial hyperparameters:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# discriminator\n",
    "# size of the input grid\n",
    "input_size = WEEKDAY_GRID_SIZE ** 2\n",
    "# discriminator outputs either 1 or 0 depending on whether it sees a real or fake grid\n",
    "discriminator_out_size = 1\n",
    "# size of final hidden layer in discriminator\n",
    "discriminator_hidden_size = 64\n",
    "\n",
    "# generator\n",
    "# size of the latent vector that is being passed to the generator\n",
    "latent_vector_dim = 15\n",
    "# size of the generator's output\n",
    "generator_out_size = input_size\n",
    "# size of the first hidden layer in the generator\n",
    "generator_hidden_size = 32\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the GAN:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# initializing the Gan with the above hyperparameters\n",
    "discriminator = Discriminator(input_size,discriminator_hidden_size,discriminator_out_size)\n",
    "generator = Generator(latent_vector_dim,generator_hidden_size,generator_out_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Discriminator: \n",
      " Discriminator(\n",
      "  (fc1): Linear(in_features=225, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ")\n",
      "The Generator: \n",
      " Generator(\n",
      "  (fc1): Linear(in_features=15, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=225, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"The Discriminator: \\n\",discriminator)\n",
    "print(\"The Generator: \\n\", generator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining Loss functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Calculating loss for the Discriminator\n",
    "def discriminator_loss(disc_out, smooth=False):\n",
    "    batch_size = disc_out.size(0)\n",
    "    if smooth:\n",
    "        # labels multiplied by 0.9\n",
    "        labels = torch.ones(batch_size) * 0.9\n",
    "    else:\n",
    "        labels = torch.ones(batch_size) # real labels = 1\n",
    "\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    return loss(disc_out.squeeze(),labels)\n",
    "\n",
    "\n",
    "def generator_loss(disc_out):\n",
    "    batch_size = disc_out.size(0)\n",
    "    labels = torch.zeros(batch_size)\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    return loss(disc_out.squeeze(),labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining optimizers:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "learning_rate = 0.002\n",
    "discriminator_opt = Adam(discriminator.parameters(),learning_rate*2)\n",
    "generator_opt = Adam(generator.parameters(),learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "# parameters for training\n",
    "num_epochs = 50\n",
    "\n",
    "# list of sample set and fake set\n",
    "sample_list = []\n",
    "loss_list = []\n",
    "\n",
    "print_every = 400\n",
    "\n",
    "# generate some fixed data that can be used to benchmark the model throughout training\n",
    "sample_size = 64\n",
    "fixed_data = np.random.binomial(1,p=0.3,size=(sample_size,WEEKDAY_GRID_SIZE))\n",
    "fixed_data = fixed_data * 2 - 1\n",
    "fixed_data = torch.from_numpy(fixed_data).float()\n",
    "fixed_data = fixed_data.to(rtx)\n",
    "\n",
    "\n",
    "# setup the dataloader\n",
    "\n",
    "train_me = torch.utils.data.DataLoader(dataset=train_data_tensor, batch_size=batch_size,num_workers=0,drop_last=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']= \"0\"\n",
    "\n",
    "from torch import multiprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  651/  950] | Discriminator Loss: 1.0718 | Generator Loss: 1.4516\n",
      "Epoch 651 was completed in 0.5803181762695313 seconds\n",
      "Epoch [  652/  950] | Discriminator Loss: 0.8801 | Generator Loss: 2.0108\n",
      "Epoch 652 was completed in 0.5122129516601562 seconds\n",
      "Epoch [  653/  950] | Discriminator Loss: 0.9667 | Generator Loss: 1.4343\n",
      "Epoch 653 was completed in 0.4634723815917969 seconds\n",
      "Epoch [  654/  950] | Discriminator Loss: 1.3071 | Generator Loss: 1.5677\n",
      "Epoch 654 was completed in 0.47597738647460935 seconds\n",
      "Epoch [  655/  950] | Discriminator Loss: 0.8799 | Generator Loss: 1.4211\n",
      "Epoch 655 was completed in 0.468177978515625 seconds\n",
      "Epoch [  656/  950] | Discriminator Loss: 1.1433 | Generator Loss: 1.2546\n",
      "Epoch 656 was completed in 0.5687163696289063 seconds\n",
      "Epoch [  657/  950] | Discriminator Loss: 1.0096 | Generator Loss: 1.4092\n",
      "Epoch 657 was completed in 0.5365704345703125 seconds\n",
      "Epoch [  658/  950] | Discriminator Loss: 0.8948 | Generator Loss: 1.4421\n",
      "Epoch 658 was completed in 0.4628138122558594 seconds\n",
      "Epoch [  659/  950] | Discriminator Loss: 0.9514 | Generator Loss: 1.3759\n",
      "Epoch 659 was completed in 0.6663793334960938 seconds\n",
      "Epoch [  660/  950] | Discriminator Loss: 0.9861 | Generator Loss: 1.2477\n",
      "Epoch 660 was completed in 0.47511489868164064 seconds\n",
      "Epoch [  661/  950] | Discriminator Loss: 1.1187 | Generator Loss: 1.3429\n",
      "Epoch 661 was completed in 0.4620770263671875 seconds\n",
      "Epoch [  662/  950] | Discriminator Loss: 1.1354 | Generator Loss: 1.3740\n",
      "Epoch 662 was completed in 0.45110202026367185 seconds\n",
      "Epoch [  663/  950] | Discriminator Loss: 1.0159 | Generator Loss: 1.3814\n",
      "Epoch 663 was completed in 0.46042184448242185 seconds\n",
      "Epoch [  664/  950] | Discriminator Loss: 0.8473 | Generator Loss: 1.5457\n",
      "Epoch 664 was completed in 0.4402769775390625 seconds\n",
      "Epoch [  665/  950] | Discriminator Loss: 0.8985 | Generator Loss: 1.4508\n",
      "Epoch 665 was completed in 0.48028146362304686 seconds\n",
      "Epoch [  666/  950] | Discriminator Loss: 0.9778 | Generator Loss: 1.5206\n",
      "Epoch 666 was completed in 0.4586153564453125 seconds\n",
      "Epoch [  667/  950] | Discriminator Loss: 0.9658 | Generator Loss: 1.4506\n",
      "Epoch 667 was completed in 0.45119500732421874 seconds\n",
      "Epoch [  668/  950] | Discriminator Loss: 1.0873 | Generator Loss: 1.4787\n",
      "Epoch 668 was completed in 0.46098193359375 seconds\n",
      "Epoch [  669/  950] | Discriminator Loss: 1.0290 | Generator Loss: 1.3147\n",
      "Epoch 669 was completed in 0.4712836303710938 seconds\n",
      "Epoch [  670/  950] | Discriminator Loss: 1.0195 | Generator Loss: 1.4412\n",
      "Epoch 670 was completed in 0.47234381103515627 seconds\n",
      "Epoch [  671/  950] | Discriminator Loss: 0.8960 | Generator Loss: 1.4865\n",
      "Epoch 671 was completed in 0.47282867431640624 seconds\n",
      "Epoch [  672/  950] | Discriminator Loss: 0.9470 | Generator Loss: 1.3984\n",
      "Epoch 672 was completed in 0.4555181884765625 seconds\n",
      "Epoch [  673/  950] | Discriminator Loss: 0.9440 | Generator Loss: 1.4655\n",
      "Epoch 673 was completed in 0.46509323120117185 seconds\n",
      "Epoch [  674/  950] | Discriminator Loss: 0.8819 | Generator Loss: 1.7980\n",
      "Epoch 674 was completed in 0.4679615478515625 seconds\n",
      "Epoch [  675/  950] | Discriminator Loss: 1.0219 | Generator Loss: 1.3715\n",
      "Epoch 675 was completed in 0.46776617431640627 seconds\n",
      "Epoch [  676/  950] | Discriminator Loss: 1.0092 | Generator Loss: 1.5167\n",
      "Epoch 676 was completed in 0.4691429443359375 seconds\n",
      "Epoch [  677/  950] | Discriminator Loss: 1.0295 | Generator Loss: 1.3533\n",
      "Epoch 677 was completed in 0.45798431396484374 seconds\n",
      "Epoch [  678/  950] | Discriminator Loss: 0.9880 | Generator Loss: 1.5772\n",
      "Epoch 678 was completed in 0.4626005859375 seconds\n",
      "Epoch [  679/  950] | Discriminator Loss: 0.8277 | Generator Loss: 1.3530\n",
      "Epoch 679 was completed in 0.4725811462402344 seconds\n",
      "Epoch [  680/  950] | Discriminator Loss: 0.9850 | Generator Loss: 1.3693\n",
      "Epoch 680 was completed in 0.44330917358398436 seconds\n",
      "Epoch [  681/  950] | Discriminator Loss: 1.0156 | Generator Loss: 1.4565\n",
      "Epoch 681 was completed in 0.47781646728515625 seconds\n",
      "Epoch [  682/  950] | Discriminator Loss: 1.0905 | Generator Loss: 1.3458\n",
      "Epoch 682 was completed in 0.4551746826171875 seconds\n",
      "Epoch [  683/  950] | Discriminator Loss: 0.9774 | Generator Loss: 1.4664\n",
      "Epoch 683 was completed in 0.4737910461425781 seconds\n",
      "Epoch [  684/  950] | Discriminator Loss: 0.9082 | Generator Loss: 1.3909\n",
      "Epoch 684 was completed in 0.55679150390625 seconds\n",
      "Epoch [  685/  950] | Discriminator Loss: 0.9451 | Generator Loss: 1.2366\n",
      "Epoch 685 was completed in 0.46490939331054687 seconds\n",
      "Epoch [  686/  950] | Discriminator Loss: 0.9769 | Generator Loss: 1.4783\n",
      "Epoch 686 was completed in 0.5536741943359375 seconds\n",
      "Epoch [  687/  950] | Discriminator Loss: 0.9476 | Generator Loss: 1.3121\n",
      "Epoch 687 was completed in 0.466912353515625 seconds\n",
      "Epoch [  688/  950] | Discriminator Loss: 0.9851 | Generator Loss: 1.5091\n",
      "Epoch 688 was completed in 0.7362898559570312 seconds\n",
      "Epoch [  689/  950] | Discriminator Loss: 1.0575 | Generator Loss: 1.2647\n",
      "Epoch 689 was completed in 0.4243138427734375 seconds\n",
      "Epoch [  690/  950] | Discriminator Loss: 0.9196 | Generator Loss: 1.2529\n",
      "Epoch 690 was completed in 0.42442547607421877 seconds\n",
      "Epoch [  691/  950] | Discriminator Loss: 1.2811 | Generator Loss: 1.2447\n",
      "Epoch 691 was completed in 0.4444164428710938 seconds\n",
      "Epoch [  692/  950] | Discriminator Loss: 1.2009 | Generator Loss: 1.5603\n",
      "Epoch 692 was completed in 0.4256625671386719 seconds\n",
      "Epoch [  693/  950] | Discriminator Loss: 0.9487 | Generator Loss: 1.2571\n",
      "Epoch 693 was completed in 0.467022216796875 seconds\n",
      "Epoch [  694/  950] | Discriminator Loss: 0.9083 | Generator Loss: 1.4338\n",
      "Epoch 694 was completed in 0.43575875854492185 seconds\n",
      "Epoch [  695/  950] | Discriminator Loss: 0.9739 | Generator Loss: 1.4458\n",
      "Epoch 695 was completed in 0.437133544921875 seconds\n",
      "Epoch [  696/  950] | Discriminator Loss: 0.9127 | Generator Loss: 1.4368\n",
      "Epoch 696 was completed in 0.43394000244140624 seconds\n",
      "Epoch [  697/  950] | Discriminator Loss: 1.0690 | Generator Loss: 1.3033\n",
      "Epoch 697 was completed in 0.4449178771972656 seconds\n",
      "Epoch [  698/  950] | Discriminator Loss: 1.0925 | Generator Loss: 1.4188\n",
      "Epoch 698 was completed in 0.4433395690917969 seconds\n",
      "Epoch [  699/  950] | Discriminator Loss: 1.1414 | Generator Loss: 1.5648\n",
      "Epoch 699 was completed in 0.4385102844238281 seconds\n",
      "Epoch [  700/  950] | Discriminator Loss: 0.9261 | Generator Loss: 1.5136\n",
      "Epoch 700 was completed in 0.4469684753417969 seconds\n",
      "Epoch [  701/  950] | Discriminator Loss: 1.0087 | Generator Loss: 1.5499\n",
      "Epoch 701 was completed in 0.42583914184570315 seconds\n",
      "Epoch [  702/  950] | Discriminator Loss: 1.0183 | Generator Loss: 1.3780\n",
      "Epoch 702 was completed in 0.426052001953125 seconds\n",
      "Epoch [  703/  950] | Discriminator Loss: 0.9383 | Generator Loss: 1.4926\n",
      "Epoch 703 was completed in 0.42843734741210937 seconds\n",
      "Epoch [  704/  950] | Discriminator Loss: 0.9278 | Generator Loss: 1.4685\n",
      "Epoch 704 was completed in 0.44897100830078124 seconds\n",
      "Epoch [  705/  950] | Discriminator Loss: 1.0186 | Generator Loss: 1.6701\n",
      "Epoch 705 was completed in 0.4567705078125 seconds\n",
      "Epoch [  706/  950] | Discriminator Loss: 0.9459 | Generator Loss: 1.4308\n",
      "Epoch 706 was completed in 0.4434374389648438 seconds\n",
      "Epoch [  707/  950] | Discriminator Loss: 0.9416 | Generator Loss: 1.3925\n",
      "Epoch 707 was completed in 0.4524618835449219 seconds\n",
      "Epoch [  708/  950] | Discriminator Loss: 0.9290 | Generator Loss: 1.5943\n",
      "Epoch 708 was completed in 0.4537096252441406 seconds\n",
      "Epoch [  709/  950] | Discriminator Loss: 1.0145 | Generator Loss: 1.3704\n",
      "Epoch 709 was completed in 0.448050537109375 seconds\n",
      "Epoch [  710/  950] | Discriminator Loss: 0.8411 | Generator Loss: 1.2888\n",
      "Epoch 710 was completed in 0.4498681640625 seconds\n",
      "Epoch [  711/  950] | Discriminator Loss: 0.9906 | Generator Loss: 1.5151\n",
      "Epoch 711 was completed in 0.42980538940429686 seconds\n",
      "Epoch [  712/  950] | Discriminator Loss: 0.9344 | Generator Loss: 1.3346\n",
      "Epoch 712 was completed in 0.4550240173339844 seconds\n",
      "Epoch [  713/  950] | Discriminator Loss: 1.0197 | Generator Loss: 1.4263\n",
      "Epoch 713 was completed in 0.4574781188964844 seconds\n",
      "Epoch [  714/  950] | Discriminator Loss: 1.0123 | Generator Loss: 1.4076\n",
      "Epoch 714 was completed in 0.4568445129394531 seconds\n",
      "Epoch [  715/  950] | Discriminator Loss: 0.9882 | Generator Loss: 1.4691\n",
      "Epoch 715 was completed in 0.43583734130859375 seconds\n",
      "Epoch [  716/  950] | Discriminator Loss: 0.9068 | Generator Loss: 1.4461\n",
      "Epoch 716 was completed in 0.461639404296875 seconds\n",
      "Epoch [  717/  950] | Discriminator Loss: 1.0335 | Generator Loss: 1.5262\n",
      "Epoch 717 was completed in 0.4568020935058594 seconds\n",
      "Epoch [  718/  950] | Discriminator Loss: 1.0433 | Generator Loss: 1.5411\n",
      "Epoch 718 was completed in 0.46098590087890623 seconds\n",
      "Epoch [  719/  950] | Discriminator Loss: 1.1643 | Generator Loss: 1.5116\n",
      "Epoch 719 was completed in 0.4426578369140625 seconds\n",
      "Epoch [  720/  950] | Discriminator Loss: 0.9754 | Generator Loss: 1.4605\n",
      "Epoch 720 was completed in 0.43837930297851563 seconds\n",
      "Epoch [  721/  950] | Discriminator Loss: 1.0300 | Generator Loss: 1.4233\n",
      "Epoch 721 was completed in 0.44806814575195314 seconds\n",
      "Epoch [  722/  950] | Discriminator Loss: 1.1081 | Generator Loss: 1.2610\n",
      "Epoch 722 was completed in 0.4650497131347656 seconds\n",
      "Epoch [  723/  950] | Discriminator Loss: 0.9959 | Generator Loss: 1.5011\n",
      "Epoch 723 was completed in 0.43929238891601563 seconds\n",
      "Epoch [  724/  950] | Discriminator Loss: 0.7789 | Generator Loss: 1.4098\n",
      "Epoch 724 was completed in 0.44148175048828125 seconds\n",
      "Epoch [  725/  950] | Discriminator Loss: 1.0329 | Generator Loss: 1.3184\n",
      "Epoch 725 was completed in 0.43600106811523437 seconds\n",
      "Epoch [  726/  950] | Discriminator Loss: 0.7769 | Generator Loss: 1.6098\n",
      "Epoch 726 was completed in 0.4422357177734375 seconds\n",
      "Epoch [  727/  950] | Discriminator Loss: 0.8697 | Generator Loss: 1.5174\n",
      "Epoch 727 was completed in 0.43890469360351564 seconds\n",
      "Epoch [  728/  950] | Discriminator Loss: 0.9574 | Generator Loss: 1.4282\n",
      "Epoch 728 was completed in 0.43430902099609375 seconds\n",
      "Epoch [  729/  950] | Discriminator Loss: 0.9926 | Generator Loss: 1.2788\n",
      "Epoch 729 was completed in 0.4407603759765625 seconds\n",
      "Epoch [  730/  950] | Discriminator Loss: 1.0040 | Generator Loss: 1.4880\n",
      "Epoch 730 was completed in 0.47863409423828124 seconds\n",
      "Epoch [  731/  950] | Discriminator Loss: 0.9592 | Generator Loss: 1.4089\n",
      "Epoch 731 was completed in 0.4389132385253906 seconds\n",
      "Epoch [  732/  950] | Discriminator Loss: 0.8633 | Generator Loss: 1.3970\n",
      "Epoch 732 was completed in 0.5129548950195313 seconds\n",
      "Epoch [  733/  950] | Discriminator Loss: 0.9687 | Generator Loss: 1.6868\n",
      "Epoch 733 was completed in 0.606147705078125 seconds\n",
      "Epoch [  734/  950] | Discriminator Loss: 0.9029 | Generator Loss: 1.4939\n",
      "Epoch 734 was completed in 0.4458068542480469 seconds\n",
      "Epoch [  735/  950] | Discriminator Loss: 0.9744 | Generator Loss: 1.5412\n",
      "Epoch 735 was completed in 0.4290966186523438 seconds\n",
      "Epoch [  736/  950] | Discriminator Loss: 1.1134 | Generator Loss: 1.5054\n",
      "Epoch 736 was completed in 0.4689851989746094 seconds\n",
      "Epoch [  737/  950] | Discriminator Loss: 0.9269 | Generator Loss: 1.5106\n",
      "Epoch 737 was completed in 0.3771485290527344 seconds\n",
      "Epoch [  738/  950] | Discriminator Loss: 0.9798 | Generator Loss: 1.4372\n",
      "Epoch 738 was completed in 0.37548468017578124 seconds\n",
      "Epoch [  739/  950] | Discriminator Loss: 0.8569 | Generator Loss: 1.3473\n",
      "Epoch 739 was completed in 0.37479364013671873 seconds\n",
      "Epoch [  740/  950] | Discriminator Loss: 0.9746 | Generator Loss: 1.5566\n",
      "Epoch 740 was completed in 0.3696566467285156 seconds\n",
      "Epoch [  741/  950] | Discriminator Loss: 0.8812 | Generator Loss: 1.5317\n",
      "Epoch 741 was completed in 0.36810476684570315 seconds\n",
      "Epoch [  742/  950] | Discriminator Loss: 1.0368 | Generator Loss: 1.4907\n",
      "Epoch 742 was completed in 0.38752816772460935 seconds\n",
      "Epoch [  743/  950] | Discriminator Loss: 0.8451 | Generator Loss: 1.6910\n",
      "Epoch 743 was completed in 0.5686361694335937 seconds\n",
      "Epoch [  744/  950] | Discriminator Loss: 0.9950 | Generator Loss: 1.4559\n",
      "Epoch 744 was completed in 0.37930413818359376 seconds\n",
      "Epoch [  745/  950] | Discriminator Loss: 1.1243 | Generator Loss: 1.3946\n",
      "Epoch 745 was completed in 0.36672454833984375 seconds\n",
      "Epoch [  746/  950] | Discriminator Loss: 0.8037 | Generator Loss: 1.5689\n",
      "Epoch 746 was completed in 0.3858747863769531 seconds\n",
      "Epoch [  747/  950] | Discriminator Loss: 0.9586 | Generator Loss: 1.3304\n",
      "Epoch 747 was completed in 0.3985857238769531 seconds\n",
      "Epoch [  748/  950] | Discriminator Loss: 0.9605 | Generator Loss: 1.3230\n",
      "Epoch 748 was completed in 0.39151889038085935 seconds\n",
      "Epoch [  749/  950] | Discriminator Loss: 1.0317 | Generator Loss: 1.5199\n",
      "Epoch 749 was completed in 0.39134060668945314 seconds\n",
      "Epoch [  750/  950] | Discriminator Loss: 0.8727 | Generator Loss: 1.4093\n",
      "Epoch 750 was completed in 0.4029301452636719 seconds\n",
      "Epoch [  751/  950] | Discriminator Loss: 1.2184 | Generator Loss: 1.2766\n",
      "Epoch 751 was completed in 0.49371307373046874 seconds\n",
      "Epoch [  752/  950] | Discriminator Loss: 1.1246 | Generator Loss: 1.4853\n",
      "Epoch 752 was completed in 0.43570355224609375 seconds\n",
      "Epoch [  753/  950] | Discriminator Loss: 0.9028 | Generator Loss: 1.5106\n",
      "Epoch 753 was completed in 0.3842916259765625 seconds\n",
      "Epoch [  754/  950] | Discriminator Loss: 0.9699 | Generator Loss: 1.3382\n",
      "Epoch 754 was completed in 0.36601968383789063 seconds\n",
      "Epoch [  755/  950] | Discriminator Loss: 1.0802 | Generator Loss: 1.4269\n",
      "Epoch 755 was completed in 0.3846594848632813 seconds\n",
      "Epoch [  756/  950] | Discriminator Loss: 1.0550 | Generator Loss: 1.3675\n",
      "Epoch 756 was completed in 0.37249295043945313 seconds\n",
      "Epoch [  757/  950] | Discriminator Loss: 1.0623 | Generator Loss: 1.5845\n",
      "Epoch 757 was completed in 0.3656466979980469 seconds\n",
      "Epoch [  758/  950] | Discriminator Loss: 1.1387 | Generator Loss: 1.3885\n",
      "Epoch 758 was completed in 0.3837366333007812 seconds\n",
      "Epoch [  759/  950] | Discriminator Loss: 1.0811 | Generator Loss: 1.3431\n",
      "Epoch 759 was completed in 0.3830262756347656 seconds\n",
      "Epoch [  760/  950] | Discriminator Loss: 1.3586 | Generator Loss: 1.6132\n",
      "Epoch 760 was completed in 0.36923779296875 seconds\n",
      "Epoch [  761/  950] | Discriminator Loss: 0.8358 | Generator Loss: 1.5179\n",
      "Epoch 761 was completed in 0.36491314697265625 seconds\n",
      "Epoch [  762/  950] | Discriminator Loss: 0.9014 | Generator Loss: 1.3880\n",
      "Epoch 762 was completed in 0.37247967529296877 seconds\n",
      "Epoch [  763/  950] | Discriminator Loss: 0.8057 | Generator Loss: 1.6248\n",
      "Epoch 763 was completed in 0.42204214477539065 seconds\n",
      "Epoch [  764/  950] | Discriminator Loss: 1.0819 | Generator Loss: 1.6234\n",
      "Epoch 764 was completed in 0.4316124267578125 seconds\n",
      "Epoch [  765/  950] | Discriminator Loss: 0.9702 | Generator Loss: 1.6776\n",
      "Epoch 765 was completed in 0.4409227294921875 seconds\n",
      "Epoch [  766/  950] | Discriminator Loss: 1.1250 | Generator Loss: 1.4697\n",
      "Epoch 766 was completed in 0.44379241943359377 seconds\n",
      "Epoch [  767/  950] | Discriminator Loss: 0.9683 | Generator Loss: 1.5365\n",
      "Epoch 767 was completed in 0.3764493103027344 seconds\n",
      "Epoch [  768/  950] | Discriminator Loss: 0.9205 | Generator Loss: 1.4033\n",
      "Epoch 768 was completed in 0.37090509033203123 seconds\n",
      "Epoch [  769/  950] | Discriminator Loss: 0.8816 | Generator Loss: 1.4709\n",
      "Epoch 769 was completed in 0.37073358154296876 seconds\n",
      "Epoch [  770/  950] | Discriminator Loss: 0.8951 | Generator Loss: 1.4727\n",
      "Epoch 770 was completed in 0.38504275512695313 seconds\n",
      "Epoch [  771/  950] | Discriminator Loss: 0.8421 | Generator Loss: 1.4131\n",
      "Epoch 771 was completed in 0.4211389465332031 seconds\n",
      "Epoch [  772/  950] | Discriminator Loss: 1.0583 | Generator Loss: 1.4221\n",
      "Epoch 772 was completed in 0.3878124084472656 seconds\n",
      "Epoch [  773/  950] | Discriminator Loss: 1.0613 | Generator Loss: 1.4533\n",
      "Epoch 773 was completed in 0.40088250732421876 seconds\n",
      "Epoch [  774/  950] | Discriminator Loss: 0.8751 | Generator Loss: 1.3968\n",
      "Epoch 774 was completed in 0.3862554016113281 seconds\n",
      "Epoch [  775/  950] | Discriminator Loss: 1.0826 | Generator Loss: 1.4394\n",
      "Epoch 775 was completed in 0.37225076293945314 seconds\n",
      "Epoch [  776/  950] | Discriminator Loss: 1.0873 | Generator Loss: 1.3099\n",
      "Epoch 776 was completed in 0.3732657165527344 seconds\n",
      "Epoch [  777/  950] | Discriminator Loss: 0.8479 | Generator Loss: 1.5257\n",
      "Epoch 777 was completed in 0.3773135070800781 seconds\n",
      "Epoch [  778/  950] | Discriminator Loss: 0.9454 | Generator Loss: 1.5597\n",
      "Epoch 778 was completed in 0.5336651000976562 seconds\n",
      "Epoch [  779/  950] | Discriminator Loss: 0.9275 | Generator Loss: 1.6622\n",
      "Epoch 779 was completed in 0.385363037109375 seconds\n",
      "Epoch [  780/  950] | Discriminator Loss: 1.0400 | Generator Loss: 1.5909\n",
      "Epoch 780 was completed in 0.38719342041015625 seconds\n",
      "Epoch [  781/  950] | Discriminator Loss: 1.1529 | Generator Loss: 1.5756\n",
      "Epoch 781 was completed in 0.369304443359375 seconds\n",
      "Epoch [  782/  950] | Discriminator Loss: 0.9209 | Generator Loss: 1.4120\n",
      "Epoch 782 was completed in 0.37982330322265623 seconds\n",
      "Epoch [  783/  950] | Discriminator Loss: 0.8005 | Generator Loss: 1.5688\n",
      "Epoch 783 was completed in 0.4610654602050781 seconds\n",
      "Epoch [  784/  950] | Discriminator Loss: 0.9001 | Generator Loss: 1.5164\n",
      "Epoch 784 was completed in 0.3890910949707031 seconds\n",
      "Epoch [  785/  950] | Discriminator Loss: 0.9242 | Generator Loss: 1.4808\n",
      "Epoch 785 was completed in 0.41695703125 seconds\n",
      "Epoch [  786/  950] | Discriminator Loss: 1.1047 | Generator Loss: 1.4047\n",
      "Epoch 786 was completed in 0.46651568603515625 seconds\n",
      "Epoch [  787/  950] | Discriminator Loss: 1.0146 | Generator Loss: 1.5695\n",
      "Epoch 787 was completed in 0.7502014770507812 seconds\n",
      "Epoch [  788/  950] | Discriminator Loss: 0.9426 | Generator Loss: 1.3476\n",
      "Epoch 788 was completed in 0.4851811218261719 seconds\n",
      "Epoch [  789/  950] | Discriminator Loss: 0.9078 | Generator Loss: 1.3691\n",
      "Epoch 789 was completed in 0.3970296630859375 seconds\n",
      "Epoch [  790/  950] | Discriminator Loss: 0.8679 | Generator Loss: 1.3929\n",
      "Epoch 790 was completed in 0.4150975646972656 seconds\n",
      "Epoch [  791/  950] | Discriminator Loss: 1.0300 | Generator Loss: 1.3518\n",
      "Epoch 791 was completed in 0.547095458984375 seconds\n",
      "Epoch [  792/  950] | Discriminator Loss: 0.7779 | Generator Loss: 1.7070\n",
      "Epoch 792 was completed in 0.36840798950195314 seconds\n",
      "Epoch [  793/  950] | Discriminator Loss: 0.9376 | Generator Loss: 1.2935\n",
      "Epoch 793 was completed in 0.3706971130371094 seconds\n",
      "Epoch [  794/  950] | Discriminator Loss: 0.9398 | Generator Loss: 1.3063\n",
      "Epoch 794 was completed in 0.3788597412109375 seconds\n",
      "Epoch [  795/  950] | Discriminator Loss: 0.8729 | Generator Loss: 1.3549\n",
      "Epoch 795 was completed in 0.3598089599609375 seconds\n",
      "Epoch [  796/  950] | Discriminator Loss: 1.0772 | Generator Loss: 1.3323\n",
      "Epoch 796 was completed in 0.3577293395996094 seconds\n",
      "Epoch [  797/  950] | Discriminator Loss: 1.0685 | Generator Loss: 1.5438\n",
      "Epoch 797 was completed in 0.4263360290527344 seconds\n",
      "Epoch [  798/  950] | Discriminator Loss: 0.9292 | Generator Loss: 1.4085\n",
      "Epoch 798 was completed in 0.422833740234375 seconds\n",
      "Epoch [  799/  950] | Discriminator Loss: 0.8082 | Generator Loss: 1.4480\n",
      "Epoch 799 was completed in 0.40781591796875 seconds\n",
      "Epoch [  800/  950] | Discriminator Loss: 1.0414 | Generator Loss: 1.4350\n",
      "Epoch 800 was completed in 0.37188446044921875 seconds\n",
      "Epoch [  801/  950] | Discriminator Loss: 0.9752 | Generator Loss: 1.5027\n",
      "Epoch 801 was completed in 0.39307220458984377 seconds\n",
      "Epoch [  802/  950] | Discriminator Loss: 0.7976 | Generator Loss: 1.3974\n",
      "Epoch 802 was completed in 0.37270211791992186 seconds\n",
      "Epoch [  803/  950] | Discriminator Loss: 0.7514 | Generator Loss: 1.3646\n",
      "Epoch 803 was completed in 0.35628762817382814 seconds\n",
      "Epoch [  804/  950] | Discriminator Loss: 0.8017 | Generator Loss: 1.3608\n",
      "Epoch 804 was completed in 0.375809326171875 seconds\n",
      "Epoch [  805/  950] | Discriminator Loss: 0.7883 | Generator Loss: 1.6556\n",
      "Epoch 805 was completed in 0.432391845703125 seconds\n",
      "Epoch [  806/  950] | Discriminator Loss: 0.8148 | Generator Loss: 1.4111\n",
      "Epoch 806 was completed in 0.3619925842285156 seconds\n",
      "Epoch [  807/  950] | Discriminator Loss: 1.1092 | Generator Loss: 1.3580\n",
      "Epoch 807 was completed in 0.373156005859375 seconds\n",
      "Epoch [  808/  950] | Discriminator Loss: 1.0563 | Generator Loss: 1.7494\n",
      "Epoch 808 was completed in 0.37964117431640626 seconds\n",
      "Epoch [  809/  950] | Discriminator Loss: 0.7985 | Generator Loss: 1.3823\n",
      "Epoch 809 was completed in 0.3820263977050781 seconds\n",
      "Epoch [  810/  950] | Discriminator Loss: 1.0003 | Generator Loss: 1.4465\n",
      "Epoch 810 was completed in 0.43883462524414063 seconds\n",
      "Epoch [  811/  950] | Discriminator Loss: 1.0646 | Generator Loss: 1.2817\n",
      "Epoch 811 was completed in 0.5458070068359375 seconds\n",
      "Epoch [  812/  950] | Discriminator Loss: 1.0784 | Generator Loss: 1.4762\n",
      "Epoch 812 was completed in 0.38824981689453125 seconds\n",
      "Epoch [  813/  950] | Discriminator Loss: 0.9013 | Generator Loss: 1.3495\n",
      "Epoch 813 was completed in 0.37960617065429686 seconds\n",
      "Epoch [  814/  950] | Discriminator Loss: 0.9700 | Generator Loss: 1.3804\n",
      "Epoch 814 was completed in 0.37622296142578127 seconds\n",
      "Epoch [  815/  950] | Discriminator Loss: 0.7668 | Generator Loss: 1.5382\n",
      "Epoch 815 was completed in 0.3872053527832031 seconds\n",
      "Epoch [  816/  950] | Discriminator Loss: 1.1216 | Generator Loss: 1.3520\n",
      "Epoch 816 was completed in 0.3652166748046875 seconds\n",
      "Epoch [  817/  950] | Discriminator Loss: 1.0339 | Generator Loss: 1.3040\n",
      "Epoch 817 was completed in 0.3650506591796875 seconds\n",
      "Epoch [  818/  950] | Discriminator Loss: 0.8650 | Generator Loss: 1.2502\n",
      "Epoch 818 was completed in 0.38393719482421873 seconds\n",
      "Epoch [  819/  950] | Discriminator Loss: 0.8896 | Generator Loss: 2.2812\n",
      "Epoch 819 was completed in 0.436401123046875 seconds\n",
      "Epoch [  820/  950] | Discriminator Loss: 0.8608 | Generator Loss: 1.3292\n",
      "Epoch 820 was completed in 0.374102783203125 seconds\n",
      "Epoch [  821/  950] | Discriminator Loss: 0.9337 | Generator Loss: 1.5628\n",
      "Epoch 821 was completed in 0.3807422180175781 seconds\n",
      "Epoch [  822/  950] | Discriminator Loss: 1.0125 | Generator Loss: 1.5358\n",
      "Epoch 822 was completed in 0.38197418212890627 seconds\n",
      "Epoch [  823/  950] | Discriminator Loss: 0.9323 | Generator Loss: 1.4366\n",
      "Epoch 823 was completed in 0.36591793823242186 seconds\n",
      "Epoch [  824/  950] | Discriminator Loss: 0.7872 | Generator Loss: 1.5055\n",
      "Epoch 824 was completed in 0.37954302978515625 seconds\n",
      "Epoch [  825/  950] | Discriminator Loss: 1.0890 | Generator Loss: 1.2822\n",
      "Epoch 825 was completed in 0.3870010681152344 seconds\n",
      "Epoch [  826/  950] | Discriminator Loss: 1.0484 | Generator Loss: 1.3251\n",
      "Epoch 826 was completed in 0.36201776123046875 seconds\n",
      "Epoch [  827/  950] | Discriminator Loss: 0.7901 | Generator Loss: 1.3944\n",
      "Epoch 827 was completed in 0.3647860412597656 seconds\n",
      "Epoch [  828/  950] | Discriminator Loss: 1.0347 | Generator Loss: 1.4979\n",
      "Epoch 828 was completed in 0.37960879516601564 seconds\n",
      "Epoch [  829/  950] | Discriminator Loss: 0.8170 | Generator Loss: 1.5266\n",
      "Epoch 829 was completed in 0.36809503173828123 seconds\n",
      "Epoch [  830/  950] | Discriminator Loss: 0.9659 | Generator Loss: 1.3958\n",
      "Epoch 830 was completed in 0.41461605834960935 seconds\n",
      "Epoch [  831/  950] | Discriminator Loss: 0.9002 | Generator Loss: 1.3099\n",
      "Epoch 831 was completed in 0.37493630981445314 seconds\n",
      "Epoch [  832/  950] | Discriminator Loss: 0.8950 | Generator Loss: 1.4017\n",
      "Epoch 832 was completed in 0.49609100341796875 seconds\n",
      "Epoch [  833/  950] | Discriminator Loss: 0.9769 | Generator Loss: 1.6046\n",
      "Epoch 833 was completed in 0.39188201904296877 seconds\n",
      "Epoch [  834/  950] | Discriminator Loss: 0.9082 | Generator Loss: 1.3422\n",
      "Epoch 834 was completed in 0.3763408203125 seconds\n",
      "Epoch [  835/  950] | Discriminator Loss: 0.8487 | Generator Loss: 1.4802\n",
      "Epoch 835 was completed in 0.3680865173339844 seconds\n",
      "Epoch [  836/  950] | Discriminator Loss: 0.8299 | Generator Loss: 1.5955\n",
      "Epoch 836 was completed in 0.3866750793457031 seconds\n",
      "Epoch [  837/  950] | Discriminator Loss: 0.7837 | Generator Loss: 1.5118\n",
      "Epoch 837 was completed in 0.38494033813476564 seconds\n",
      "Epoch [  838/  950] | Discriminator Loss: 0.9420 | Generator Loss: 1.4650\n",
      "Epoch 838 was completed in 0.3871956481933594 seconds\n",
      "Epoch [  839/  950] | Discriminator Loss: 0.9868 | Generator Loss: 1.3442\n",
      "Epoch 839 was completed in 0.39761474609375 seconds\n",
      "Epoch [  840/  950] | Discriminator Loss: 0.9154 | Generator Loss: 1.4035\n",
      "Epoch 840 was completed in 0.42441946411132814 seconds\n",
      "Epoch [  841/  950] | Discriminator Loss: 1.1789 | Generator Loss: 1.3040\n",
      "Epoch 841 was completed in 0.369332763671875 seconds\n",
      "Epoch [  842/  950] | Discriminator Loss: 1.1334 | Generator Loss: 1.5043\n",
      "Epoch 842 was completed in 0.38939312744140625 seconds\n",
      "Epoch [  843/  950] | Discriminator Loss: 0.8202 | Generator Loss: 1.4519\n",
      "Epoch 843 was completed in 0.46533203125 seconds\n",
      "Epoch [  844/  950] | Discriminator Loss: 1.0373 | Generator Loss: 1.3033\n",
      "Epoch 844 was completed in 0.37776202392578123 seconds\n",
      "Epoch [  845/  950] | Discriminator Loss: 0.8895 | Generator Loss: 1.4995\n",
      "Epoch 845 was completed in 0.39273574829101565 seconds\n",
      "Epoch [  846/  950] | Discriminator Loss: 0.8170 | Generator Loss: 1.5325\n",
      "Epoch 846 was completed in 0.3653602294921875 seconds\n",
      "Epoch [  847/  950] | Discriminator Loss: 0.9540 | Generator Loss: 1.3929\n",
      "Epoch 847 was completed in 0.36765481567382813 seconds\n",
      "Epoch [  848/  950] | Discriminator Loss: 0.8064 | Generator Loss: 1.4119\n",
      "Epoch 848 was completed in 0.402180419921875 seconds\n",
      "Epoch [  849/  950] | Discriminator Loss: 1.0411 | Generator Loss: 1.4389\n",
      "Epoch 849 was completed in 0.3867035827636719 seconds\n",
      "Epoch [  850/  950] | Discriminator Loss: 0.9660 | Generator Loss: 1.3465\n",
      "Epoch 850 was completed in 0.3842607421875 seconds\n",
      "Epoch [  851/  950] | Discriminator Loss: 0.9616 | Generator Loss: 1.3739\n",
      "Epoch 851 was completed in 0.392293212890625 seconds\n",
      "Epoch [  852/  950] | Discriminator Loss: 0.9153 | Generator Loss: 1.3776\n",
      "Epoch 852 was completed in 0.472529052734375 seconds\n",
      "Epoch [  853/  950] | Discriminator Loss: 0.8678 | Generator Loss: 1.3787\n",
      "Epoch 853 was completed in 0.3928532104492187 seconds\n",
      "Epoch [  854/  950] | Discriminator Loss: 0.8228 | Generator Loss: 1.4631\n",
      "Epoch 854 was completed in 0.38481533813476565 seconds\n",
      "Epoch [  855/  950] | Discriminator Loss: 0.8696 | Generator Loss: 1.3708\n",
      "Epoch 855 was completed in 0.5633284912109375 seconds\n",
      "Epoch [  856/  950] | Discriminator Loss: 0.8894 | Generator Loss: 1.3597\n",
      "Epoch 856 was completed in 0.3933475646972656 seconds\n",
      "Epoch [  857/  950] | Discriminator Loss: 0.8268 | Generator Loss: 1.4535\n",
      "Epoch 857 was completed in 0.4394603576660156 seconds\n",
      "Epoch [  858/  950] | Discriminator Loss: 0.9024 | Generator Loss: 1.4187\n",
      "Epoch 858 was completed in 0.410985595703125 seconds\n",
      "Epoch [  859/  950] | Discriminator Loss: 1.0173 | Generator Loss: 1.5997\n",
      "Epoch 859 was completed in 0.4318360595703125 seconds\n",
      "Epoch [  860/  950] | Discriminator Loss: 0.9662 | Generator Loss: 1.5043\n",
      "Epoch 860 was completed in 0.41803549194335937 seconds\n",
      "Epoch [  861/  950] | Discriminator Loss: 1.0367 | Generator Loss: 1.3903\n",
      "Epoch 861 was completed in 0.42526788330078125 seconds\n",
      "Epoch [  862/  950] | Discriminator Loss: 0.9320 | Generator Loss: 1.3653\n",
      "Epoch 862 was completed in 0.43680868530273437 seconds\n",
      "Epoch [  863/  950] | Discriminator Loss: 0.9367 | Generator Loss: 2.2480\n",
      "Epoch 863 was completed in 0.42957000732421874 seconds\n",
      "Epoch [  864/  950] | Discriminator Loss: 1.0414 | Generator Loss: 1.3668\n",
      "Epoch 864 was completed in 0.4413008117675781 seconds\n",
      "Epoch [  865/  950] | Discriminator Loss: 0.9126 | Generator Loss: 1.5389\n",
      "Epoch 865 was completed in 0.45247808837890624 seconds\n",
      "Epoch [  866/  950] | Discriminator Loss: 0.9377 | Generator Loss: 1.3250\n",
      "Epoch 866 was completed in 0.38943719482421874 seconds\n",
      "Epoch [  867/  950] | Discriminator Loss: 0.8062 | Generator Loss: 1.3947\n",
      "Epoch 867 was completed in 0.36869757080078125 seconds\n",
      "Epoch [  868/  950] | Discriminator Loss: 0.9434 | Generator Loss: 1.5595\n",
      "Epoch 868 was completed in 0.44585467529296874 seconds\n",
      "Epoch [  869/  950] | Discriminator Loss: 0.9846 | Generator Loss: 1.4674\n",
      "Epoch 869 was completed in 0.38852169799804687 seconds\n",
      "Epoch [  870/  950] | Discriminator Loss: 1.2034 | Generator Loss: 1.3753\n",
      "Epoch 870 was completed in 0.3812452087402344 seconds\n",
      "Epoch [  871/  950] | Discriminator Loss: 0.8193 | Generator Loss: 1.4962\n",
      "Epoch 871 was completed in 0.37772799682617186 seconds\n",
      "Epoch [  872/  950] | Discriminator Loss: 0.9339 | Generator Loss: 1.4546\n",
      "Epoch 872 was completed in 0.37866012573242186 seconds\n",
      "Epoch [  873/  950] | Discriminator Loss: 0.9892 | Generator Loss: 1.3710\n",
      "Epoch 873 was completed in 0.38660784912109375 seconds\n",
      "Epoch [  874/  950] | Discriminator Loss: 0.7918 | Generator Loss: 1.3782\n",
      "Epoch 874 was completed in 0.4250615234375 seconds\n",
      "Epoch [  875/  950] | Discriminator Loss: 0.9293 | Generator Loss: 1.4482\n",
      "Epoch 875 was completed in 0.3878420715332031 seconds\n",
      "Epoch [  876/  950] | Discriminator Loss: 0.8969 | Generator Loss: 1.4045\n",
      "Epoch 876 was completed in 0.3890379333496094 seconds\n",
      "Epoch [  877/  950] | Discriminator Loss: 0.8862 | Generator Loss: 1.4587\n",
      "Epoch 877 was completed in 0.3714249267578125 seconds\n",
      "Epoch [  878/  950] | Discriminator Loss: 0.9361 | Generator Loss: 1.3749\n",
      "Epoch 878 was completed in 0.3742154541015625 seconds\n",
      "Epoch [  879/  950] | Discriminator Loss: 0.9072 | Generator Loss: 1.3525\n",
      "Epoch 879 was completed in 0.3739146728515625 seconds\n",
      "Epoch [  880/  950] | Discriminator Loss: 1.0627 | Generator Loss: 1.5128\n",
      "Epoch 880 was completed in 0.36826309204101565 seconds\n",
      "Epoch [  881/  950] | Discriminator Loss: 0.9164 | Generator Loss: 1.4176\n",
      "Epoch 881 was completed in 0.3842628479003906 seconds\n",
      "Epoch [  882/  950] | Discriminator Loss: 0.9782 | Generator Loss: 1.3021\n",
      "Epoch 882 was completed in 0.5133272705078125 seconds\n",
      "Epoch [  883/  950] | Discriminator Loss: 0.8539 | Generator Loss: 1.3411\n",
      "Epoch 883 was completed in 0.37378817749023435 seconds\n",
      "Epoch [  884/  950] | Discriminator Loss: 0.8505 | Generator Loss: 1.5837\n",
      "Epoch 884 was completed in 0.37656640625 seconds\n",
      "Epoch [  885/  950] | Discriminator Loss: 1.0423 | Generator Loss: 1.4146\n",
      "Epoch 885 was completed in 0.37943099975585937 seconds\n",
      "Epoch [  886/  950] | Discriminator Loss: 0.9130 | Generator Loss: 1.9291\n",
      "Epoch 886 was completed in 0.3653900756835938 seconds\n",
      "Epoch [  887/  950] | Discriminator Loss: 0.9311 | Generator Loss: 1.4199\n",
      "Epoch 887 was completed in 0.3635634155273437 seconds\n",
      "Epoch [  888/  950] | Discriminator Loss: 0.8995 | Generator Loss: 1.3902\n",
      "Epoch 888 was completed in 0.554228271484375 seconds\n",
      "Epoch [  889/  950] | Discriminator Loss: 0.8976 | Generator Loss: 1.4059\n",
      "Epoch 889 was completed in 0.36544644165039064 seconds\n",
      "Epoch [  890/  950] | Discriminator Loss: 0.7469 | Generator Loss: 1.6380\n",
      "Epoch 890 was completed in 0.3848424377441406 seconds\n",
      "Epoch [  891/  950] | Discriminator Loss: 1.0588 | Generator Loss: 1.4108\n",
      "Epoch 891 was completed in 0.3661095886230469 seconds\n",
      "Epoch [  892/  950] | Discriminator Loss: 0.9609 | Generator Loss: 1.4161\n",
      "Epoch 892 was completed in 0.39637399291992187 seconds\n",
      "Epoch [  893/  950] | Discriminator Loss: 1.2172 | Generator Loss: 1.5032\n",
      "Epoch 893 was completed in 0.369601806640625 seconds\n",
      "Epoch [  894/  950] | Discriminator Loss: 1.0359 | Generator Loss: 1.3595\n",
      "Epoch 894 was completed in 0.3669999084472656 seconds\n",
      "Epoch [  895/  950] | Discriminator Loss: 0.9145 | Generator Loss: 1.4463\n",
      "Epoch 895 was completed in 0.38031210327148435 seconds\n",
      "Epoch [  896/  950] | Discriminator Loss: 0.9978 | Generator Loss: 1.4390\n",
      "Epoch 896 was completed in 0.3724051818847656 seconds\n",
      "Epoch [  897/  950] | Discriminator Loss: 0.8286 | Generator Loss: 1.6276\n",
      "Epoch 897 was completed in 0.36309634399414065 seconds\n",
      "Epoch [  898/  950] | Discriminator Loss: 0.8396 | Generator Loss: 1.4202\n",
      "Epoch 898 was completed in 0.36878277587890623 seconds\n",
      "Epoch [  899/  950] | Discriminator Loss: 0.9115 | Generator Loss: 1.5619\n",
      "Epoch 899 was completed in 0.4586885681152344 seconds\n",
      "Epoch [  900/  950] | Discriminator Loss: 0.7459 | Generator Loss: 1.6577\n",
      "Epoch 900 was completed in 0.381507080078125 seconds\n",
      "Epoch [  901/  950] | Discriminator Loss: 0.9397 | Generator Loss: 1.4781\n",
      "Epoch 901 was completed in 0.5056302795410156 seconds\n",
      "Epoch [  902/  950] | Discriminator Loss: 1.0563 | Generator Loss: 1.4836\n",
      "Epoch 902 was completed in 0.38539422607421875 seconds\n",
      "Epoch [  903/  950] | Discriminator Loss: 0.8568 | Generator Loss: 1.3689\n",
      "Epoch 903 was completed in 0.4362896423339844 seconds\n",
      "Epoch [  904/  950] | Discriminator Loss: 0.7752 | Generator Loss: 1.5143\n",
      "Epoch 904 was completed in 0.3666925659179687 seconds\n",
      "Epoch [  905/  950] | Discriminator Loss: 0.9372 | Generator Loss: 1.3437\n",
      "Epoch 905 was completed in 0.37387799072265626 seconds\n",
      "Epoch [  906/  950] | Discriminator Loss: 0.9225 | Generator Loss: 1.3792\n",
      "Epoch 906 was completed in 0.38524575805664063 seconds\n",
      "Epoch [  907/  950] | Discriminator Loss: 1.0052 | Generator Loss: 1.4995\n",
      "Epoch 907 was completed in 0.3764671325683594 seconds\n",
      "Epoch [  908/  950] | Discriminator Loss: 0.8398 | Generator Loss: 1.4971\n",
      "Epoch 908 was completed in 0.36608099365234376 seconds\n",
      "Epoch [  909/  950] | Discriminator Loss: 0.9057 | Generator Loss: 1.3910\n",
      "Epoch 909 was completed in 0.41736328125 seconds\n",
      "Epoch [  910/  950] | Discriminator Loss: 0.9052 | Generator Loss: 1.4658\n",
      "Epoch 910 was completed in 0.4446566162109375 seconds\n",
      "Epoch [  911/  950] | Discriminator Loss: 0.8418 | Generator Loss: 1.5753\n",
      "Epoch 911 was completed in 0.43379913330078124 seconds\n",
      "Epoch [  912/  950] | Discriminator Loss: 0.8599 | Generator Loss: 1.3717\n",
      "Epoch 912 was completed in 0.440459228515625 seconds\n",
      "Epoch [  913/  950] | Discriminator Loss: 0.9610 | Generator Loss: 1.5035\n",
      "Epoch 913 was completed in 0.40036505126953126 seconds\n",
      "Epoch [  914/  950] | Discriminator Loss: 0.8182 | Generator Loss: 1.5085\n",
      "Epoch 914 was completed in 0.4981365966796875 seconds\n",
      "Epoch [  915/  950] | Discriminator Loss: 0.8510 | Generator Loss: 1.4691\n",
      "Epoch 915 was completed in 0.3835900268554687 seconds\n",
      "Epoch [  916/  950] | Discriminator Loss: 0.9402 | Generator Loss: 1.4702\n",
      "Epoch 916 was completed in 0.39793560791015625 seconds\n",
      "Epoch [  917/  950] | Discriminator Loss: 0.8125 | Generator Loss: 1.5421\n",
      "Epoch 917 was completed in 0.38855548095703124 seconds\n",
      "Epoch [  918/  950] | Discriminator Loss: 1.0725 | Generator Loss: 1.4770\n",
      "Epoch 918 was completed in 0.40183224487304686 seconds\n",
      "Epoch [  919/  950] | Discriminator Loss: 1.0010 | Generator Loss: 1.4933\n",
      "Epoch 919 was completed in 0.386240478515625 seconds\n",
      "Epoch [  920/  950] | Discriminator Loss: 0.9066 | Generator Loss: 1.7135\n",
      "Epoch 920 was completed in 0.38508096313476564 seconds\n",
      "Epoch [  921/  950] | Discriminator Loss: 0.7918 | Generator Loss: 1.5760\n",
      "Epoch 921 was completed in 0.37347137451171875 seconds\n",
      "Epoch [  922/  950] | Discriminator Loss: 0.9926 | Generator Loss: 1.4138\n",
      "Epoch 922 was completed in 0.4570616149902344 seconds\n",
      "Epoch [  923/  950] | Discriminator Loss: 0.9432 | Generator Loss: 1.5503\n",
      "Epoch 923 was completed in 0.390871337890625 seconds\n",
      "Epoch [  924/  950] | Discriminator Loss: 1.0122 | Generator Loss: 1.4933\n",
      "Epoch 924 was completed in 0.39356997680664063 seconds\n",
      "Epoch [  925/  950] | Discriminator Loss: 0.7015 | Generator Loss: 1.6370\n",
      "Epoch 925 was completed in 0.3875727233886719 seconds\n",
      "Epoch [  926/  950] | Discriminator Loss: 0.9710 | Generator Loss: 1.6822\n",
      "Epoch 926 was completed in 0.3957012939453125 seconds\n",
      "Epoch [  927/  950] | Discriminator Loss: 0.9749 | Generator Loss: 1.5876\n",
      "Epoch 927 was completed in 0.3920187072753906 seconds\n",
      "Epoch [  928/  950] | Discriminator Loss: 0.8085 | Generator Loss: 1.4035\n",
      "Epoch 928 was completed in 0.3842243347167969 seconds\n",
      "Epoch [  929/  950] | Discriminator Loss: 0.9916 | Generator Loss: 1.4450\n",
      "Epoch 929 was completed in 0.3996588134765625 seconds\n",
      "Epoch [  930/  950] | Discriminator Loss: 1.1067 | Generator Loss: 1.4017\n",
      "Epoch 930 was completed in 0.3746374206542969 seconds\n",
      "Epoch [  931/  950] | Discriminator Loss: 0.9933 | Generator Loss: 1.6215\n",
      "Epoch 931 was completed in 0.37647442626953126 seconds\n",
      "Epoch [  932/  950] | Discriminator Loss: 0.9063 | Generator Loss: 1.5134\n",
      "Epoch 932 was completed in 0.3764010925292969 seconds\n",
      "Epoch [  933/  950] | Discriminator Loss: 0.9474 | Generator Loss: 1.6822\n",
      "Epoch 933 was completed in 0.3896056213378906 seconds\n",
      "Epoch [  934/  950] | Discriminator Loss: 0.9239 | Generator Loss: 1.5414\n",
      "Epoch 934 was completed in 0.3885621948242188 seconds\n",
      "Epoch [  935/  950] | Discriminator Loss: 0.7135 | Generator Loss: 1.7838\n",
      "Epoch 935 was completed in 0.3807493591308594 seconds\n",
      "Epoch [  936/  950] | Discriminator Loss: 0.8624 | Generator Loss: 1.5800\n",
      "Epoch 936 was completed in 0.395291015625 seconds\n",
      "Epoch [  937/  950] | Discriminator Loss: 0.7957 | Generator Loss: 1.5617\n",
      "Epoch 937 was completed in 0.5572333374023437 seconds\n",
      "Epoch [  938/  950] | Discriminator Loss: 1.0021 | Generator Loss: 1.5301\n",
      "Epoch 938 was completed in 0.37368667602539063 seconds\n",
      "Epoch [  939/  950] | Discriminator Loss: 0.9056 | Generator Loss: 1.5193\n",
      "Epoch 939 was completed in 0.3846251220703125 seconds\n",
      "Epoch [  940/  950] | Discriminator Loss: 0.8591 | Generator Loss: 1.7346\n",
      "Epoch 940 was completed in 0.408031982421875 seconds\n",
      "Epoch [  941/  950] | Discriminator Loss: 0.9556 | Generator Loss: 1.5615\n",
      "Epoch 941 was completed in 0.4195552368164063 seconds\n",
      "Epoch [  942/  950] | Discriminator Loss: 0.9928 | Generator Loss: 1.3544\n",
      "Epoch 942 was completed in 0.4459853515625 seconds\n",
      "Epoch [  943/  950] | Discriminator Loss: 0.8265 | Generator Loss: 1.5733\n",
      "Epoch 943 was completed in 0.44016357421875 seconds\n",
      "Epoch [  944/  950] | Discriminator Loss: 0.8333 | Generator Loss: 1.4265\n",
      "Epoch 944 was completed in 0.45302859497070314 seconds\n",
      "Epoch [  945/  950] | Discriminator Loss: 0.8821 | Generator Loss: 1.4760\n",
      "Epoch 945 was completed in 0.4409659423828125 seconds\n",
      "Epoch [  946/  950] | Discriminator Loss: 0.9436 | Generator Loss: 1.6379\n",
      "Epoch 946 was completed in 0.45983071899414063 seconds\n",
      "Epoch [  947/  950] | Discriminator Loss: 0.7566 | Generator Loss: 1.6565\n",
      "Epoch 947 was completed in 0.41093609619140625 seconds\n",
      "Epoch [  948/  950] | Discriminator Loss: 0.7571 | Generator Loss: 1.5461\n",
      "Epoch 948 was completed in 0.43187344360351565 seconds\n",
      "Epoch [  949/  950] | Discriminator Loss: 0.8935 | Generator Loss: 1.5085\n",
      "Epoch 949 was completed in 0.5123172607421875 seconds\n",
      "Epoch [  950/  950] | Discriminator Loss: 0.8709 | Generator Loss: 1.6081\n",
      "Epoch 950 was completed in 0.442239013671875 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 25 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training time!\n",
    "import random\n",
    "num_epochs = 300\n",
    "discriminator.train()\n",
    "generator.train()\n",
    "init_total_completed = total_completed\n",
    "for epoch in range(num_epochs):\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "    start_event.record()\n",
    "\n",
    "    for b_index, real_grids in enumerate(train_me):\n",
    "\n",
    "        # get batch size from size of real_grids\n",
    "        batch_size = real_grids.size(0)\n",
    "\n",
    "        real_grids = real_grids*2-1 # rescale input images from [0,1] to [-1,1]\n",
    "\n",
    "        # DISC Training\n",
    "        discriminator_opt.zero_grad(set_to_none=True)\n",
    "\n",
    "\n",
    "\n",
    "        # first, train on real images\n",
    "        disc_real = discriminator(real_grids)\n",
    "        disc_real_loss = discriminator_loss(disc_real,smooth=False)\n",
    "\n",
    "        # next, to train on fake images\n",
    "        # start by generating fake images\n",
    "        fake_grid_input = np.random.binomial(1,p=0.3,size=(batch_size,WEEKDAY_GRID_SIZE,WEEKDAY_GRID_SIZE))\n",
    "        fake_grid_input = fake_grid_input*2-1\n",
    "        fake_grid_input = torch.from_numpy(fake_grid_input).float()\n",
    "        fake_grid_input =fake_grid_input.to(rtx)\n",
    "        fake_grids = generator(fake_grid_input)\n",
    "\n",
    "        # Compute the disc loss on the fake images\n",
    "        disc_fake = discriminator(fake_grids)\n",
    "        disc_fake_loss = generator_loss(disc_fake)\n",
    "\n",
    "        # sum the losses\n",
    "        disc_loss = disc_real_loss + disc_fake_loss\n",
    "\n",
    "        # backpropagation\n",
    "        disc_loss.backward()\n",
    "        discriminator_opt.step()\n",
    "\n",
    "\n",
    "        ### Generator Training\n",
    "        generator_opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        # train on fake images with flipped labels\n",
    "        # first, generate fake images\n",
    "        fake_grid_input = np.random.binomial(1,p=0.4,size=(batch_size,WEEKDAY_GRID_SIZE,WEEKDAY_GRID_SIZE))\n",
    "        fake_grid_input = fake_grid_input*2-1\n",
    "        fake_grid_input = torch.from_numpy(fake_grid_input).float()\n",
    "        fake_grid_input = fake_grid_input.to(rtx)\n",
    "        fake_grids = generator(fake_grid_input)\n",
    "\n",
    "        # compute the discriminator losses on fake images, and flip the labels by using the disc_loss function\n",
    "        disc_fake = discriminator(fake_grids)\n",
    "        gen_loss = discriminator_loss(disc_fake)\n",
    "\n",
    "        # backpropagation\n",
    "        gen_loss.backward()\n",
    "        generator_opt.step()\n",
    "\n",
    "        # Log progress to stdout\n",
    "        # if b_index % print_every==0:\n",
    "        #\n",
    "        #     # print discriminator and generator loss\n",
    "        #     print('Epoch [{:5d}/{:5d}] | Discriminator Loss: {:6.4f} | Generator Loss: {:6.4f}'.format(epoch+1, num_epochs,\n",
    "        #                                                                            disc_loss.item(), gen_loss.item()))\n",
    "\n",
    "    end_event.record()\n",
    "    torch.cuda.synchronize()  # Wait for the events to be recorded!\n",
    "    elapsed_time_ms = start_event.elapsed_time(end_event)\n",
    "    total_completed = total_completed +1\n",
    "    print('Epoch [{:5d}/{:5d}] | Discriminator Loss: {:6.4f} | Generator Loss: {:6.4f}'.format(total_completed, init_total_completed  + num_epochs,\n",
    "                                                                                   disc_loss.item(), gen_loss.item()))\n",
    "    print(f'Epoch {total_completed} was completed in {elapsed_time_ms/1000} seconds')\n",
    "    ## Append discriminator loss and gen loss after each epoch\n",
    "    loss_list.append((disc_loss.item(),gen_loss.item()))\n",
    "\n",
    "    # generate images with generator and save image\n",
    "    # set generator in eval mode\n",
    "    generator.eval()\n",
    "\n",
    "    #generate samples\n",
    "    new_samples = generator(fixed_data)\n",
    "    new_samples_detached = [sample.detach().cpu().numpy() for sample in new_samples]\n",
    "    sample_list.append(new_samples)\n",
    "\n",
    "    sample_sample = random.sample(new_samples_detached,25)\n",
    "\n",
    "    # print the image\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,1+i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(new_samples_detached[i].reshape(15,15),cmap=\"Greys\")\n",
    "    plt.savefig(f'../exports/gridgan-images/generation_{str.zfill(str(total_completed),4)}.png',)\n",
    "\n",
    "    if total_completed % 10 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "    # return generator to training mode\n",
    "    generator.train()\n",
    "\n",
    "with open('../bin/train_samples.pickle','wb') as f:\n",
    "    pkl.dump(sample_list,f)\n",
    "\n",
    "with open('../bin/gan_model_tuple.pickle','wb') as f:\n",
    "    pkl.dump((discriminator,generator),f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch-rapids",
   "language": "python",
   "display_name": "Shor.tz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
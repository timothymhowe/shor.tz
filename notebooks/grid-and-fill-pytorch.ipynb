{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, I detail the method by which a grid is generated and subsequently filled."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "WEEKDAY_GRID_SIZE = 15"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "#  if a square is empty, 0.  If a square is black, 1.\n",
    "def bin_gridify(raw_grids):\n",
    "    binary_grids = []\n",
    "    for grid in raw_grids:\n",
    "        new_grid = [1 if x == \".\" else 0 for x in grid ]\n",
    "        binary_grids = binary_grids + [new_grid]\n",
    "    return binary_grids\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "dow_dict = pickle.load(open('../bin/pickles/dow_dict.pickle','rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "data_set = []\n",
    "for day in dow_dict.keys():\n",
    "    grid_list = dow_dict[day]\n",
    "    grid_list = bin_gridify(grid_list)\n",
    "    data_set = data_set + [grid_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mon = data_set[0]\n",
    "mon = [np.array(grid).reshape(15,15) for grid in mon if len(grid) == (15*15)]\n",
    "\n",
    "tue = data_set[1]\n",
    "tue = [np.array(grid).reshape(15,15) for grid in tue if len(grid) == (15*15)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "# defining a function that checks the symmetry of the grid\n",
    "def check_symmetry(dim,grid):\n",
    "    leng = dim*dim\n",
    "    half = (leng-1)//2\n",
    "    array = grid.reshape(leng,)\n",
    "    front = array[:half]\n",
    "    back = array[-half:]\n",
    "    return (front == np.flip(back)).all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_symmetry(15,mon[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 25 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    plt.subplot(5,5,1+i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mon[i],cmap=\"Greys\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version is: 1.12.1.post200\n",
      "Torchvision version is: 0.13.1\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "print(\"PyTorch version is:\",torch.__version__)\n",
    "print(\"Torchvision version is:\",torchvision.__version__)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "num_workers = 32 #\n",
    "batch_size = 64 # number of samples per batch\n",
    "# transform = transforms.ToTensor()\n",
    "train_data = np.array(mon+tue)\n",
    "train_data_tensor = torch.from_numpy(train_data)\n",
    "labels = np.array([1]*len(train_data))\n",
    "\n",
    "# creating a loader to feed the models training data\n",
    "train_me = torch.utils.data.DataLoader(train_data_tensor, batch_size=batch_size,num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [150]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m train_demo \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(train_me)\n\u001B[0;32m----> 2\u001B[0m images, \u001B[38;5;241m*\u001B[39m_ \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_demo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m img \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqueeze(images[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m15\u001B[39m])\n\u001B[1;32m      4\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mimshow(img,cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGreys\u001B[39m\u001B[38;5;124m'\u001B[39m,aspect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch-rapids/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    678\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    679\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 681\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    684\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    685\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch-rapids/lib/python3.9/site-packages/torch/utils/data/dataloader.py:720\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    719\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 720\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    721\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    722\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch-rapids/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter._next_index\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    670\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_index\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 671\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sampler_iter\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch-rapids/lib/python3.9/site-packages/torch/utils/data/sampler.py:247\u001B[0m, in \u001B[0;36mBatchSampler.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    245\u001B[0m batch \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size\n\u001B[1;32m    246\u001B[0m idx_in_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 247\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampler:\n\u001B[1;32m    248\u001B[0m     batch[idx_in_batch] \u001B[38;5;241m=\u001B[39m idx\n\u001B[1;32m    249\u001B[0m     idx_in_batch \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'type' object is not iterable"
     ]
    }
   ],
   "source": [
    "train_demo = iter(train_me)\n",
    "images, *_ = train_demo.next()\n",
    "img = np.squeeze(images[0:15])\n",
    "fig = plt.imshow(img,cmap='Greys',aspect=True)\n",
    "# images.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating custom class for the grid dataset in pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GridDataset(Dataset):\n",
    "    def __init__(self,annotations_file,train_grids,transform=None, target_transform=None):\n",
    "        self.grid_labels = np.array([1]*len(train_grids))\n",
    "        self.grid_array = train_grids\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grid_labels)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        grid = self.grid_array.iloc[idx]\n",
    "        label = self.grid_labels.iloc[idx]\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(grid)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,input_size,hidden_dim,output_size):\n",
    "        super(Discriminator,self).__init__()\n",
    "\n",
    "        # 3 hidden layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim*4)\n",
    "        self.fc2 = nn.Linear(hidden_dim*4,hidden_dim*2)\n",
    "        self.fc3 = nn.Linear(hidden_dim*2,hidden_dim)\n",
    "\n",
    "        # output layer\n",
    "        self.fc4 = nn.Linear(hidden_dim,output_size)\n",
    "\n",
    "        # defining a dropout layer to prevent overfitting.\n",
    "        self.dropout= nn.Dropout(0.2)\n",
    "\n",
    "    def forward (self,x):\n",
    "        x = x.view(-1,28*28)\n",
    "        x = F.leaky_relu(self.fc1(x),0.2) # input\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # return result of output layer\n",
    "        return self.fc4(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "# Defining a generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "         super(Generator, self).__init__()\n",
    "\n",
    "         # Defining all hidden layers for the generator\n",
    "         self.fc1 = nn.Linear(input_size, hidden_dim)\n",
    "         self.fc2 = nn.Linear(hidden_dim, hidden_dim*2)\n",
    "         self.fc3 = nn.Linear(hidden_dim*2, hidden_dim*4)\n",
    "\n",
    "         # Defining the output layer for the generator\n",
    "         self.fc4 = nn.Linear(hidden_dim*4, output_size)\n",
    "\n",
    "         # defining the droput for the generator, which prevents overfitting.\n",
    "         self.dropout = nn.Dropout(0.3)\n",
    "    def forward(self, x):\n",
    "         # creating all hidden layers\n",
    "         x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n",
    "         x = self.dropout(x) # dropout to reduce overfit\n",
    "         x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "         x = self.dropout(x)\n",
    "         x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "         x = self.dropout(x)\n",
    "\n",
    "         # return result of the output layer\n",
    "         return F.tanh(self.fc4(x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining initial hyperparameters:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "# discriminator\n",
    "# size of the input grid\n",
    "input_size = WEEKDAY_GRID_SIZE ** 2\n",
    "# discriminator outputs either 1 or 0 depending on whether it sees a real or fake grid\n",
    "discriminator_out_size = 1\n",
    "# size of final hidden layer in discriminator\n",
    "discriminator_hidden_size = 64\n",
    "\n",
    "# generator\n",
    "# size of the latent vector that is being passed to the generator\n",
    "latent_vector_dim = 100\n",
    "# size of the generator's output\n",
    "generator_out_size = input_size\n",
    "# size of the first hidden layer in the generator\n",
    "generator_hidden_size = 64\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the GAN:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "# initializing the Gan with the above hyperparameters\n",
    "discriminator = Discriminator(input_size,discriminator_hidden_size,discriminator_out_size)\n",
    "generator = Generator(latent_vector_dim,generator_hidden_size,generator_out_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Discriminator: \n",
      " Discriminator(\n",
      "  (fc1): Linear(in_features=225, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "The Generator: \n",
      " Generator(\n",
      "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=225, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"The Discriminator: \\n\",discriminator)\n",
    "print(\"The Generator: \\n\", generator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining Loss functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "# Calculating loss for the Discriminator\n",
    "def discriminator_loss(disc_out, smooth=False):\n",
    "    batch_size = disc_out.size(0)\n",
    "    if smooth:\n",
    "        # labels multiplied by 0.9\n",
    "        labels = torch.ones(batch_size) * 0.9\n",
    "    else:\n",
    "        labels = torch.ones(batch_size) # real labels = 1\n",
    "\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    return loss(disc_out.squeeze(),labels)\n",
    "\n",
    "\n",
    "def generator_loss(disc_out):\n",
    "    batch_size = disc_out.size(0)\n",
    "    labels = torch.zeros(batch_size)\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    return loss(disc_out.squeeze(),labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining optimizers:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "learning_rate = 0.002\n",
    "discriminator_opt = Adam(discriminator.parameters(),learning_rate)\n",
    "generator_opt = Adam(generator.parameters(),learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "# parameters for training\n",
    "num_epochs = 100\n",
    "\n",
    "# list of sample set and fake set\n",
    "sample_list = []\n",
    "loss_list = []\n",
    "\n",
    "print_every = 400\n",
    "\n",
    "# generate some fixed data that can be used to benchmark the model throughout training\n",
    "sample_size = 32\n",
    "fixed_data = np.random.uniform(-1,1,size=(sample_size,latent_vector_dim))\n",
    "fixed_data = torch.from_numpy(fixed_data).float()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [153]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(train_data_tensor, batch_size\u001B[38;5;241m=\u001B[39mbatch_size,num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,sampler\u001B[38;5;241m=\u001B[39m\u001B[38;5;28menumerate\u001B[39m,generator\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1738\u001B[39m,drop_last\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m----> 7\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m b_index, (real_grids,_) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_me):\n\u001B[1;32m      8\u001B[0m \n\u001B[1;32m      9\u001B[0m         \u001B[38;5;66;03m# get batch size from size of real_grids\u001B[39;00m\n\u001B[1;32m     10\u001B[0m         batch_size \u001B[38;5;241m=\u001B[39m real_grids\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     12\u001B[0m         real_grids \u001B[38;5;241m=\u001B[39m real_grids\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;66;03m# rescale input images from [0,1] to [-1,1]\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch-rapids/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    678\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    679\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 681\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    684\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    685\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch-rapids/lib/python3.9/site-packages/torch/utils/data/dataloader.py:720\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    719\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 720\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    721\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    722\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch-rapids/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter._next_index\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    670\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_index\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 671\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sampler_iter\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch-rapids/lib/python3.9/site-packages/torch/utils/data/sampler.py:247\u001B[0m, in \u001B[0;36mBatchSampler.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    245\u001B[0m batch \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size\n\u001B[1;32m    246\u001B[0m idx_in_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 247\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampler:\n\u001B[1;32m    248\u001B[0m     batch[idx_in_batch] \u001B[38;5;241m=\u001B[39m idx\n\u001B[1;32m    249\u001B[0m     idx_in_batch \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'type' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Training time!\n",
    "discriminator.train()\n",
    "generator.train()\n",
    "train_loader = torch.utils.data.DataLoader(train_data_tensor, batch_size=batch_size,num_workers=0,sampler=enumerate,generator=1738,drop_last=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for b_index, (real_grids,_) in enumerate(train_me):\n",
    "\n",
    "        # get batch size from size of real_grids\n",
    "        batch_size = real_grids.size(0)\n",
    "\n",
    "        real_grids = real_grids*2-1 # rescale input images from [0,1] to [-1,1]\n",
    "\n",
    "        # DISC Training\n",
    "        discriminator_opt.zero_grad()\n",
    "\n",
    "        # first, train on real images\n",
    "        disc_real = discriminator(real_grids)\n",
    "        disc_real_loss = discriminator_loss(disc_real,smooth=False)\n",
    "\n",
    "        # next, to train on fake images\n",
    "        # start by generating fake images\n",
    "        fake_grid_input = np.random.binomial(1,p=0.4,size=(batch_size,WEEKDAY_GRID_SIZE,WEEKDAY_GRID_SIZE))\n",
    "        fake_grid_input = fake_grid_input*2-1\n",
    "        fake_grid_input = torch.from_numpy(fake_grids)\n",
    "        fake_grids = generator(fake_grid_input)\n",
    "\n",
    "        # Compute the disc loss on the fake images\n",
    "        disc_fake = discriminator(fake_grids)\n",
    "        disc_fake_loss = generator_loss(disc_fake)\n",
    "\n",
    "        # sum the losses\n",
    "        disc_loss = disc_real_loss + disc_fake_loss\n",
    "\n",
    "        # backpropagation\n",
    "        disc_loss.backward()\n",
    "        discriminator_opt.step()\n",
    "\n",
    "\n",
    "        ### Generator Training\n",
    "        generator_opt.zero_grad()\n",
    "\n",
    "        # train on fake images with flipped labels\n",
    "        # first, generate fake images\n",
    "        fake_grid_input = np.random.binomial(1,p=0.4,size=(batch_size,WEEKDAY_GRID_SIZE,WEEKDAY_GRID_SIZE))\n",
    "        fake_grid_input = fake_grid_input*2-1\n",
    "        fake_grid_input = torch.from_numpy(fake_grid_input)\n",
    "        fake_grids = generator(fake_grid_input)\n",
    "\n",
    "        # compute the discriminator losses on fake images, and flip the labels by using the disc_loss function\n",
    "        disc_fake = discriminator(fake_grids)\n",
    "        gen_loss = disc_loss(disc_fake)\n",
    "\n",
    "        # backpropagation\n",
    "        gen_loss.backward()\n",
    "        generator_opt.step()\n",
    "\n",
    "        # Log progress to stdout\n",
    "        if b_index % print_every==0:\n",
    "\n",
    "            # print discriminator and generator loss\n",
    "            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                                   disc_loss.item(), gen_loss.item()))\n",
    "\n",
    "    ## Append discriminator loss and gen loss after each epoch\n",
    "    loss_list.append((disc_loss.item(),gen_loss.item()))\n",
    "\n",
    "    # generate images with generator and save image\n",
    "    # set generator in eval mode\n",
    "    generator.eval()\n",
    "\n",
    "    #generate samples\n",
    "    new_samples = generator(fixed_data)\n",
    "    sample_list.append(new_samples)\n",
    "\n",
    "    # print the image\n",
    "    for i in range(32):\n",
    "        plt.subplot(8,4,1+i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(mon[i],cmap=\"Greys\")\n",
    "    plt.savefig(f'../exports/gridgan-images/generation_{str.zfill(epoch())}.png',)\n",
    "\n",
    "    # return generator to training mode\n",
    "    generator.train()\n",
    "\n",
    "    with open('../bin/train_samples.pickle','wb') as f:\n",
    "        pkl.dump(sample_list,f)\n",
    "\n",
    "    with open('../bin/gan_model_tuple.pickle','wb') as f:\n",
    "        pkl.dump((discriminator,generator),f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [145]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m (a,b) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28menumerate\u001B[39m(train_me)\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "(a,b) = enumerate(train_me)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x7f7ce70ca610>"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_me."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch-rapids",
   "language": "python",
   "display_name": "Shor.tz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}